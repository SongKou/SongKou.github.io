+++
title = 'CDN_Cache_Cluster_communication'
date = 2022-01-16T12:29:04+08:00
draft = true
categories = ['Network']
tags = ['CDN']
+++

4.2 Cache 集群协同交互方法

Cache 服务器集群内部协同交互的主要目标是在各个服务器节点间建立良好的通信通道，以及时沟通服务器上的内容缓存情况，通过集群中服务器间的协作为用户提供良好的服务体验。

Cache 服务器集群之间的通信可以分为松散耦合和紧密耦合两大类。其中基于网络消息的松散耦合的 Cache 通信协议包括：ICP、HTCP、Cache Digest、Cache Pre-filling 等，采用特定数据结构管理的紧密耦合的 Cache 通信协议以 CARP 为代表。下面我们对这些通信协议做扼要的介绍，重点说明其工作原理和优缺点，有兴趣的读者可查找相关资料详细了解技术细节。
4.2.1 ICP

RFC 2186 ICP（Internet Cache Protocol）定义了一种轻量级的消息格式，被用于在 Cache 服务器之间互相查询 Web 资源信息，以确定当前被请求的资源是否存在于其他服务器上。当一台 Cache 服务器向其邻居发出 Web 对象（主要是 URL 信息）查询请求时，接收到查询请求的服务器通过反馈包含了「命中（hit）」或者「失效（miss）」信息的 ICP 应答说明被查询的对象是否保存在自己这里。

ICP 普遍是基于 UDP 协议实现的，虽然这并不是协议本身的规定。这主要是考虑到 ICP over UDP 的方式更加适合 Web Cache 这类应用，因为一个 ICP 查询的请求和应答必须在非常短的时间内（例如一两秒之内）完成交互，这样才能保证 Cache 服务器能够快速从邻居服务器上获得 Web 对象。如果使用 UDP 协议的请求服务器在接收应答时发现错误，那么可能意味着服务器之间的网络发生了拥塞或者是被断开，而相应的应答服务器也就不再适合被选为请求服务器的邻居。另外，相比较支持可靠传输的 TCP 协议，UDP 协议包的规格更小，也更符合 ICP 轻量级消息格式的要求。当然，除上述这些适用性之外，ICP 也必须考虑 UDP 协议带来的安全问题。

需要注意的是，ICP 的请求和应答中并不包含与资源相关的 HTTP 头信息，例如访问控制、缓存指示等。因此尽管 Cache 服务器在通过 HTTP 协议获取相关资源前已经查询过了资源的可用性，但是仍旧可能发生 Cache 失效的情况（例如存在于 Cache 服务器上的某些 Web 对象并不允许邻居服务器对它的访问）。

ICP 已经有较长时间的历史了，当前已经发展至 ICP v2，大部分现有的 Cache 服务器也都能够以一定形式实现对 ICP 的支持。
4.2.2 HTCP

HTCP（Hypertext Caching Protocol）是用于发现 HTTP 高速缓存（Cache）服务器和缓存数据的协议，在 RFC 2756 中定义。它能够管理一组 HTTP Cache 服务器并监控相关的缓存活动。

HTCP 的运行机制与 ICP 类似，都是通过向邻居服务器发出查询请求并获得应答来反映 Web 对象在集群中的缓存情况。但是，与 ICP v2 只能包含 Web 对象的 URI 不同，HTCP 请求和应答中可以包含有完整的 HTTP 头文件的信息，这使得当后续的 HTTP 请求需要访问同样的资源时，HTCP 能够做出更精确的应答。另外，HTCP 采用了可变长度的消息格式，并扩展了 Cache 管理功能，例如能够监控远程 Cache 的增删、请求立即删除、发送 Web 对象提示（例如被缓存对象的第三方存放位置以及那些不可被缓存或者不可用的 Web 对象的第三方存放位置）。

一个 HTCP 消息包括了三个部分：头信息、数据、认证。其中，头信息部分主要用于告知消息的长度和协议的版本；数据部分主要用于描述具体的 HTCP 消息，其中包含各种 HTCP 操作码和操作数据，例如用于测试缓存应答是否存在的 TST、用于告知邻居更新缓存目标头部信息的 SET、用于告知邻居从其 Cache 中清除目标的 CLR、监控邻居 Cache 活动的 MON 等；认证部分是可选的，主要用于体现事务操作的认证信息。

在具体实现中，HTCP 消息可以通过 UDP 报文或者 TCP 连接传送。其中 UDP 报文是必须被支持的，而 TCP 协议则主要用于进行协议的调试。HTCP 一般选用 HMAC-MD5 共享密钥认证，因为如果不使用密码认证，该协议比较容易受到攻击。
4.2.3 Cache Digest

Cache Digest 的出现主要是为了解决 ICP 和 HTCP 协议在使用过程中的网络延迟和拥塞问题。Cache Digest 并不采用基于请求-问答模式的带内查询方法，而是在服务器之间建立对等关系，即每台 Cache 服务器上都保存了它的所有邻居的缓存信息摘要。当接收到用户的 Web 对象访问请求时，Cache Digest 直接在本地的 Cache 内容摘要中检索，并获知该被请求的 Web 对象 URI 是否在某个邻居 Cache 里。

相比较 ICP 和 HTCP，Cache Digest 实际上是一种空间换时间的思路，即利用 Cache 服务器本地的存储空间保存邻居服务器的 Cache 内容信息，从而节省每次查询过程中在网络上的传输延迟。对于 Cache Digest 而言，摘要算法的选择格外重要，考虑到摘要文件的传输时延和存储开销，所以摘要文件的规格要尽量小，但这样也可能导致查询的精度降低，算法的选择是一个平衡取舍问题。

使用 Cache Digest 需要特别考虑安全问题。比如服务器 A 生成了一个摘要文件，并将其发送给与之对等的服务器 B，B 会根据这份摘要去不同邻居获取内容。也就是说，A 的这份摘要文件能够直接影响流向 B 的网络流量，如果摘要文件被恶意篡改，B 就会面临严重的安全问题。为降低这种风险，可以考虑只允许服务器采用「拉」的方式主动从其他服务器上获得摘要文件，而不是被动地接收由别的服务器「推」来的摘要文件。
4.2.4 Cache Pre-filling

Cache Pre-filling 实现的是一种推送 Cache 内容的机制，它能够很好地应用在 IP 多播网络上。它使得预先被选定的资源能够被同时插入到目标多播组中的所有 Cache 服务器中，从而实现集群中各台服务器保存内容的同步。

当前，Cache Pre-filling 技术已经多有实现，特别是应用在卫星通信的场景中，它最大的优点在于能够同时向多个分布的地面卫星接收器高速传输大容量数据，从而在网络传输速度不高的情况下极大地改善数据访问体验。但总体而言，Cache Pre-filling 当前还缺乏统一的标准，各相关厂商普遍都是基于实际场景需要各自开发专用设备实现这类推送 Cache 技术，或者是在某些通用 Cache 设备上增加相关的专用模块。
4.2.5 CARP

CARP（Cache Array Routing Protocol）本质上是一个分布式的缓存协议，通过建立哈希函数用于划分 Cache 服务器集群的 URL 空间。CARP 的核心是为集群定义了一张 Cache 服务器阵列成员表，以及一个用于向 Cache 服务器上分发缓存 URL 信息的哈希函数。CARP 为用户提供 Web 对象 URL 的获取路径，该路径是根据服务器阵列成员的名称和相应的 URL 内容通过哈希操作而产生的，这就意味着对于任何特定的 URL 请求，都能够准确地知道其所需的信息存储在阵列中哪个 Cache 服务器上，而不用理会这是一个此前刚刚被请求并被缓存的信息，还是首次被点击需要传递和缓存的信息。

CARP 通过哈希算法将用户对 URL 的请求准确路由到服务器阵列中的任一成员上，消除了阵列中重复的缓存数据，实现了对 Cache 资源的高效定位。因为无须考虑更多的不可逆性和加密要求，CARP 采用的算法非常简单，具有极高的性能。

由于 CARP 被很多商用系统使用，我们来详细了解一下它的工作过程。首先，对 Cache 服务器阵列中的各个成员的名称字符串实施逐位左循环移动若干位的操作形成其对应的哈希 ID，这些信息将被补充到阵列成员表中，并在每台服务器中保存；其次，对众多的 URL 字符串采用类似的算法进行操作，获得相应的 URL 哈希值；然后，每个 URL 哈希值都要和各台服务器的哈希 ID 做异或操作并乘以一个常数，其得到的乘积再逐位左循环移动指定位数以获得相应的分数；最后，CARP 对分数值进行大小比较，并最终将 URL 对应的内容分配到与之操作具有最高分数的服务器上。在某台 Cache 服务器收到用户的 URL 请求时，它会将该 URL 对应的 URL 哈希值与本地保存的集群阵列成员表中各台服务器的哈希 ID 进行哈希运算，再根据分数的高低判定该 URL 内容应该在哪台服务器上。

考虑到不同 Cache 服务器的处理能力差异，CARP 在哈希算法中还引入了负载因子，以明确阵列中不同服务器能够承担的工作负载并为其分派合适的 URL 缓存内容，实现性能的优化。

CARP 是一种紧耦合的 Cache 通信方式，相比较基于网络消息的松散耦合的 Cache 通信，CARP 的主要优势体现在：

（1）无须资源查询的请求和应答过程，避免网络影响，降低传输开销。

（2）消除了重复缓存数据，系统中每个 URL 内容只保留一份，节省空间。

（3）具有更好的扩展性，因为无须和众多其他 Cache 服务器进行网络交互。

（4）可以灵活增删服务器节点，哈希算法的应用能够最小化节点数量变化导致的数据分布影响。

（5）能够确保所有的 URL 数据都能够有效地缓存在系统中
