+++
title = 'Load_Balancing'
date = 2022-03-20T21:29:04+08:00
draft = true
categories = ['Network']
tags = ['CDN', 'Load_Balancing']

+++


4.3 负载均衡技术的实现

负载均衡（Server Load Balance），含义是将负载（工作任务）进行平衡、分摊到多个操作单元上进行执行，从而实现整个系统共同完成任务。

负载均衡提供了一种廉价又有效的方法扩展网络设备和服务器的带宽、增加吞吐量、加强网络数据处理能力、提高网络的灵活性和可用性。根据负载均衡实施目的的不同，可以把负载均衡分为两种。一种是任务分担，大量的并发访问或数据流量分担到多台设备上分别处理，每台设备都完成一个相对完整的请求响应过程；另一种是协同计算，把一个重负载的计算任务分担到多台设备上做并行处理，各台设备处理结束后，将结果进行汇总计算。

如前文所述，负载均衡的关键在于能够使任务负载在集群中的服务器上被尽可能均衡地承载，避免出现集群中某几台服务器超载而其他服务器闲置的情况。在实现了负载均衡的集群中，多台服务器通过网络连接在一起，通过在集群前端部署负载均衡设备，根据预先配置的均衡策略将用户请求在集群中分发，并维护服务器的可用性。负载均衡实现的示意图如图 4-3 所示。

图 4-3 负载均衡实现示意图

从图 4-3 中可以看出，负载均衡设备能够在服务器之前截获到客户端发来的用户请求，然后按照预先配置的负载均衡策略将其分发到合适的后端服务器上。因此，客户端发出的业务请求报文首先都要发送到负载均衡设备的 IP 地址上，因为该地址并不负责处理实际的业务操作，因此通常将该地址称为虚拟 IP 地址，而将后端真正的业务服务器称为真实服务器。负载均衡设备通过虚拟 IP 地址和客户端通信，再将负载合理地分配给真实服务器。

在很长一段时间内，负载均衡主要是在 OSI 七层网络协议栈的第四层展开，而随着业务类型的日益丰富、用户精细化需求的不断提升和深度剖析技术的极大完善，基于第七层的负载均衡技术已逐渐成为主流。
4.3.1 负载均衡关键技术

负载均衡的目标是合理地将用户请求分发到合适的服务器上，从而达到系统处理的最优方案，其关键技术包括：负载均衡分发、会话持续性保证、服务器健康检测等。

1.负载均衡调度算法

负载均衡调度算法的目标是将用户请求和相关流量高效、正确地分发到处于正常工作状态的服务器上，使得各台服务器尽可能地保持负载均衡。

目前商用系统中已经使用了非常丰富的负载均衡调度算法，总体而言调度算法可以分为静态算法和动态算法两大类。静态算法是指按照预先设定的策略进行分发，而不考虑当前服务器的实际负载情况，其实现比较简单快捷。典型的静态算法包括轮询、加权轮询、随机、加权随机、基于源 IP 的 Hash、基于源 IP 端口的 Hash、基于目的 IP 的 Hash、基于 UDP 报文净荷的 Hash 等；动态算法能够根据各服务器实际运行中的负载情况进行连接分发，具有更优的均衡效果，典型的动态算法包括基于最小连接、基于加权最小连接、最小响应时间等。

（1）轮询（Round Robin）：依次将请求分发到不同的服务器上，使得各台服务器平均分担用户的连接请求，该算法适用于集群中各服务器性能相当而无明显优劣差异的场景。

（2）加权轮询（Weighted Round Robin）：依次将请求分发到不同的服务器上，其中权值大的分配较多请求，权值小的分配较少请求，该算法利用权值标识服务器间的性能差异，适用于各服务器间性能不一的场景。

（3）随机（Random）：随机地将请求分发到不同的服务器上，从统计学角度看，调度的结果为各台服务器平均分担用户的连接请求，该算法适用于集群中各服务器性能相当而无明显优劣差异的场景。

（4）加权随机（Weighted Random）：随机地将请求分发到不同的服务器上，从统计学角度看，调度的结果为各台服务器按照权值比重分担用户的连接请求，该算法适用于集群中各服务器性能存在差异的场景。

（5）基于源 IP 的 Hash（Source IP Hashing）：通过一个 Hash 函数将来自同一个源 IP 地址的请求映射到一台服务器上，该算法适用于需要保证来自同一用户的请求被分发到同一台服务器的场景。

（6）基于源 IP 端口的 Hash（Source IP and Source Port Hashing）：通过一个 Hash 函数将来自同一个源 IP 地址和源端口号的请求映射到一台服务器上，该算法适用于需要保证来自同一用户同一业务的请求被分发到同一台服务器的场景。

（7）基于目的 IP 的 Hash（Destination IP Hashing）：通过一个 Hash 函数将去往同一个目的 IP 地址的请求映射到一台服务器上，该算法适用于需要保证到达同一目的地的请求被分发到同一台服务器的场景。

（8）基于 UDP 报文净荷的 Hash（UDP Packet Load Hashing）：通过一个 Hash 函数将 UDP 报文载荷中特定字段的内容相同的请求映射到一台服务器上，该算法适用于需要保证 UDP 报文载荷中特定字段内容相同的请求被分发到同一台服务器的场景。

（9）最小连接（Least Connection）：根据当前各台服务器的连接数估算服务器的负载情况，把新的连接分配给连接数最小的服务器。该算法能够将连接保持时长差异较大的用户请求合理地分发到各台服务器上，适用于集群中各服务器性能相当、无明显优劣差异，而且不同用户发起的连接保持时长差异较大的场景。

（10）加权最小连接（Weighted Least Connection）：调度新连接时尽可能使得服务器上已经建立的活动连接数和服务器权值成一定比例，其中权值标识了服务器间的性能差异，该算法适用于集群中各服务器性能存在差异，而且不同用户发起的连接保持时长差异较大的场景。

（11）最小响应时间（Least Response Time）：调度新连接时尽可能选择对用户请求响应时间短的服务器，该算法适用于用户请求对服务器响应时间要求较高的场景。

不同的调度算法所实现的负载均衡效果不尽相同，可以根据实际应用场景的需求，选用不同的算法。例如在 Web 服务器集群可以采用轮询算法获得较高的访问响应，FTP 服务器集群可以采用最小连接算法减轻单台服务器的压力，报税等专用业务集群可以采用基于源 IP 端口的 Hash 算法确保用户访问的持续性。

除了上述传统的分发算法外，近年来针对内容分析的分发算法越来越受到负载均衡设备厂商的重视。举个例子来说，对于 Web 网站服务器集群而言，其使用的负载均衡设备不仅需要能够根据 IP 地址和默认 80 端口分发 HTTP 流量，还需要根据 HTTP 报文头或内容分配到指定服务器。这类设备可以对 HTTP 报文进行分析，获得 Accept-Encoding、Accept-language、Host、Request-Method、URL-file、URL-function、User-agent 等信息，并以此为依据向合适的服务器分发请求。

2.会话持续性保证技术

会话持续性保证技术的目标是保证在一定时间段内某一个用户与系统的会话只交给同一台服务器处理，这一点在满足网银、网购等应用场景的需求时格外重要。

在实际的应用中，一次业务交互可能包含有多个 TCP 连接，不同业务的 TCP 连接有各自的特点。比如 FTP 业务的连接包含了一个控制通道和多个数据通道，这些 TCP 连接之间存在显式的关联关系，即数据通道的 TCP 连接是通过控制通道协商得来的。因此，在负载均衡过程中只需要分析 FTP 业务的控制通道报文就可以获得各个数据通道的信息并进而将这些信息纳入到一个会话中，从而保证所有通道都访问同一台服务器。但是，对于 HTTP 业务而言，其各个 TCP 连接间就不存在这种显式的关联关系，在第 3 章中已经了解到，HTTP 是一个无状态协议。但是在某些场景中又要求一系列 HTTP 消息之间建立关联，比如 HTTP 网络购物，这只能依靠携带在数据报文中的相关信息表达连接之间的关联，例如源 IP 地址、Cookie 数据等。

这里讲的技术是负载均衡设备通过分析四层 TCP 数据包和七层 HTTP 消息中存在的隐式关联关系，确定处理连接请求的服务器，从而实现会话持续性保证。该领域的主要思路包括如下几点。

（1）基于源 IP 地址的持续性保持：主要用于四层负载均衡，确保来自同一个源 IP 的业务能够分配到同一台服务器中。当负载均衡设备接收到某 IP 的首次请求时，建立持续性表项，记录下为该 IP 分配的服务器情况，在会话表项的生存周期内，后续具有相同源 IP 地址的业务报文都将被发往该服务器处理。

（2）基于 Cookie 数据的持续性保持：主要用于七层负载均衡，用以确保同一会话的报文能够被分配到同一台服务器中。其中，根据服务器的应答报文中是否携带含有服务器信息的 Set-Cookie 字段，又可分为采用 Cookie 插入或者 Cookie 截取的方法。

● Cookie 插入保持：服务器的应答报文中不携带含有服务器信息的 Set-Cookie 字段，而由负载均衡设备在报文中添加相关信息。这样，客户端就会在请求报文中加入含有该服务器信息的 Cookie 字段，进而由负载均衡设备按照 Cookie 字段中的服务器信息将请求报文发给相应的服务器。

● Cookie 截取保持：服务器的应答报文中携带含有服务器信息的 Set-Cookie 字段，负载均衡设备根据用户配置的 Cookie 标识截取应答报文中的 Cookie 值。对于后续的客户端请求报文，如果能够匹配负载均衡设备中保存的 Cookie 值，则负载均衡设备直接将请求报文发给相应的服务器。

（3）基于 SIP 报文 Call-ID 的持续性保持：主要用于七层负载均衡，用以确保 IP 会话中会话标识相同的 SIP 报文能够被分配到同一台服务器中。当负载均衡设备接收到某一个客户端的某一个业务的首次请求时，建立持续性表项，记录下为该客户端分配的服务器情况，在会话表项的生存周期内，后续具有相同会话标识的 SIP 业务报文都将被发往该服务器处理。

（4）基于 HTTP 报文头的持续性保持：主要用于七层负载均衡，用以确保 HTTP 报文头中的某些关键信息相同的报文能够被分配到同一台服务器中。当负载均衡设备接收到某一个客户端的某一个业务的首次请求时，根据 HTTP 报文头关键字建立持续性表项，记录下为该客户端分配的服务器情况，在会话表项的生存周期内，后续具有相同 HTTP 报文头信息的报文都将被发往该服务器处理。至于什么信息被设置为关键字，是配置负载均衡策略的一个步骤。

3.服务器健康检测技术

服务器健康检测技术的目标是及时发现和剔除工作状态不正常的服务器，保留「健康」的服务器池为用户提供服务。服务器健康检测的核心是定期对服务器的工作状态进行探测，收集相应信息，及时隔离工作状态异常的服务器。另外，除了标识服务器能否继续工作外，健康检测的结果还可以统计出服务器的响应时间，作为负载均衡设备选择服务器的依据。

当前，负载均衡领域已经使用了非常多的服务器健康检测技术，主要方法是通过发送不同类型的协议报文并通过检查能否接收到正确的应答来判定服务器的健康程度，主要包括以下几项。

（1）ICMP：向集群中的服务器发送 ICMP Echo 报文，若正确收到 ICMP Reply，则证明服务器 ICMP 协议处理正常。

（2）TCP：向集群中的服务器的某个端口发起 TCP 连接建立请求，若成功三次握手建立 TCP 连接，则证明服务器 TCP 协议处理正常。

（3）HTTP：与集群中的服务器的 HTTP 端口（默认情况为 80 端口）建立 TCP 连接，然后发出 HTTP 请求，若收到的 HTTP 应答内容正确，则证明服务器 HTTP 协议处理正常。

（4）FTP：与集群中的服务器的 FTP 端口（默认情况为 21 端口）建立 TCP 连接，然后获取服务器上的文件，若收到的文件内容正确，则证明服务器 FTP 协议处理正常。

（5）DNS：向集群中的 DNS 服务器发出 DNS 请求，若收到正确的 DNS 解析应答，则证明服务器 DNS 协议处理正常。

（6）RADIUS：向集群中的服务器发送 RADIUS 认证请求，若收到认证成功的应答，则证明服务器 RADIUS 协议处理正常。

（7）SSL：向集群中的服务器发起 SSL 连接建立请求，若成功建立 SSL 连接，则证明服务器 SSL 协议处理正常。

针对不同的服务器功用，可以选择相应的健康检测方法，例如 ICMP 检测适用于服务器主机层面的健康检测，TCP 检测适用于业务层面的健康检测，HTTP 和 FTP 等方面的检测适用于应用层面的健康检测。一旦发现服务器处理出现异常，即可以将其上分担的负载通过负载均衡机制转移到合适的「健康」服务器上，保证整个集群系统的可用性。
4.3.2 负载均衡部署方式

负载均衡设备在具体实现中分直连和旁挂两种部署方式。此外，为了提高网络可用性，负载均衡设备的双机热备部署也是十分必要的。

1.常用负载均衡部署方式

（1）直连部署方式

直连部署方式比较简单，就是将负载均衡设备直接部署在报文必经之路上，作为服务器和客户端之间的路由设备，来往报文均直接由负载均衡设备进行路由，其部署示意如图 4-4 所示。

图 4-4 直连方式的负载均衡设备部署示意

（2）旁挂部署方式

负载均衡设备的旁挂部署方式是指负载均衡设备并不作为服务器和客户端之间的路由设备，而只是旁挂在通用路由设备上，例如以板卡的形式插在路由设备的扩展插槽中，其部署示意如图 4-5 所示。

图 4-5 旁挂方式的负载均衡设备部署示意

在如图 4-5 所示的旁挂模式中，用于中转报文的路由交换设备的配置非常重要，因为客户端发送给服务器的请求流量如果要首先被负载均衡设备接收，就必须在路由交换设备上预先配置到负载均衡设备虚拟 IP 地址的路由信息。

一般情况下，旁挂部署方式中从服务器返回给客户端的流量可以不经过负载均衡设备，而是直接通过路由交换设备发给客户端。如果仍然希望流量先返回负载均衡设备，那么需要一些特殊的操作步骤，例如：令服务器和负载均衡设备处于同一个二层网络中，服务器将其网关设置为负载均衡设备；在路由交换设备上配置路由策略，将从服务器返回的流量定向到负载均衡设备上；负载均衡设备在转发客户端流量时进行源地址 NAT 转换。这些处理操作在负载均衡设备需要承担更多功用（例如 SSL 加速）的时候，是非常重要的。

2.双机热备部署方式

无论是直连还是旁挂的部署方式，负载均衡设备始终处于网络的关键路径上，因此负载均衡设备的稳定性和安全性直接影响网络的可用性。为了避免出现负载均衡设备故障导致整个系统的单点故障，负载均衡设备必须支持双机热备，即在两台负载均衡设备之间通过备份链路进行对端设备上的业务备份，以保证两台设备的业务状态始终保持一致。当其中一台设备发生故障时，业务流量能够被及时切换到另一台设备上。因为另一台设备已经备份了故障设备上的全部业务信息，所以业务流量能够继续由该设备处理并分发，从而尽可能避免造成业务中断。

负载均衡设备的双机热备的实现主要有主备模式和负载分担模式两种类型。

（1）主备模式：两台负载均衡设备中，一台作为主设备，另一台作为备份设备。主设备负责处理所有业务，并将产生的业务信息通过备份链路传送给备份设备。备份设备并不处理实际业务，而只用于备份。当主设备出现故障时，备份设备及时接替主设备处理业务，在负责正常处理新发起的负载均衡业务的同时也要保证此前正在进行中的负载均衡业务不会中断。

（2）负载分担模式：两台负载均衡设备均为主设备，都能够处理业务流量，同时又作为彼此的备份设备，负责备份对端设备产生的业务信息。当其中一台设备出现故障后，另一设备将负责处理全部业务，在负责正常处理新发起的负载均衡业务的同时，也要保证此前正在进行中的负载均衡业务不会中断。
4.3.3 服务器负载均衡

服务器负载均衡是将客户端请求在集群中的服务器上实现均衡分发的技术。按照位于七层网络协议栈的不同层的划分，服务器负载均衡可以分为四层（L4）负载均衡和七层（L7）负载均衡两种。其中，L4 负载均衡是基于流的服务器负载均衡，能够对报文进行逐流分发，即将同一条流的报文分发给同一台服务器；L7 负载均衡是基于内容的服务器负载均衡，能够对七层报文内容进行深度解析，并根据其中的关键字进行逐包转发，按照既定策略将连接导向指定的服务器。两者相比较，L4 负载均衡因无法对七层业务实现按内容分发，限制了它的适用范围，因此 L7 负载均衡受到了业界的极大重视并日渐成为服务器负载均衡的主流。

1.四层负载均衡

L4 负载均衡的实现主要有 NAT 方式和 DR 方式两种类型，它们适用于不同的应用场景。

（1）NAT 方式 L4 负载均衡

网络地址转换（NAT，Network Address Translation）属于广域网接入技术，它是一种将私有（保留）地址转化为合法 IP 地址的转换技术，被广泛应用于各种类型互联网接入方式和各种类型的网络中。

采用 NAT 方式实现的 L4 服务器负载均衡，后端服务器可以位于不同的物理位置和不同的局域网内。负载均衡设备在分发服务请求时，需要进行虚拟 IP 地址和目的 IP 地址转换，再通过路由将报文转发给具有相应目的地址的服务器。NAT 方式 L4 负载均衡的典型组网如图 4-6 所示。

图 4-6 NAT 方式 L4 负载均衡的典型组网

图 4-6 中的主要组件包括如下几项。

● 负载均衡设备：负责将客户端服务请求分发到服务器集群中的具体服务器进行处理。

● 真实服务器：负责响应和处理各种客户端服务请求的服务器，多台服务器构成集群。

● 虚拟 IP 地址：集群对外提供的公网 IP 地址供客户端请求服务时使用。

● 服务器 IP 地址：服务器的 IP 地址供负载均衡设备分发服务请求时使用。这个 IP 地址可以是公网 IP，也可以是私网 IP。

NAT 方式 L4 服务器负载均衡的工作原理如图 4-7 所示。

图 4-7 NAT 方式 L4 负载均衡的工作流程

工作流程是这样的：

（1）负载均衡设备负责接收客户端发送至虚拟 IP 地址的服务请求。

（2）负载均衡设备通过服务器可用性验证、会话持续性保证等对负载均衡算法进行调度，选择出负责响应和处理该请求的真实服务器。

（3）负载均衡设备用真实服务器的 IP 地址改写请求报文的目标地址，再将请求发送给选定的真实服务器。

（4）真实服务器的响应报文首先通过负载均衡设备。

（5）负载均衡设备将响应报文的源地址修改为虚拟 IP 地址，再返回给客户端。

这种方法使用了网络地址转换（NAT）技术实现 L4 负载均衡，它具有组网灵活，适用于多种组网类型的特征。该方法对服务器没有额外的要求，不需要修改服务器的配置。

（2）DR 方式 L4 负载均衡

DR（Direct Routing）是另一种 L4 服务器负载均衡的实现方式。与 NAT 方式的 L4 负载均衡不同，DR 方式只有客户端发出的服务请求报文需要通过负载均衡设备，而服务器发出的响应报文则无须通过，这样能够有效减少负载均衡设备的负载压力，避免负载均衡设备成为系统性能瓶颈。

DR 方式下，负载均衡设备在分发服务器请求时，不采用改变请求目的 IP 地址的方法，而是将报文的目的 MAC 地址替换为服务器的 MAC 地址，然后直接将报文转发给服务器。DR 方式 L4 负载均衡的典型组网如图 4-8 所示。

图 4-8 DR 方式 L4 负载均衡的典型组网

从图 4-8 中可以看出，DR 方式 L4 服务器负载均衡的实现方案与 NAT 方式类似，区别是负载均衡设备是以旁挂形式与交换机相连接的，而且集群中每台处理用户请求的服务器都拥有单独的虚拟 IP 地址。

DR 方式 L4 负载均衡的原理是为负载均衡设备和真实服务器同时配置虚拟 IP 地址，但是要求真实服务器的虚拟 IP 地址不能响应 ARP 请求，例如在环回接口上配置虚拟 IP 地址。用于响应服务请求的服务器上除了虚拟 IP 地址，还需要配置一个真实的 IP 地址用于和负载均衡设备通信。负载均衡设备要和真实服务器同处于一个二层网络内。因为服务器的虚拟 IP 地址不能响应 ARP 请求，所以从客户端发送给虚拟 IP 地址的报文将由负载均衡设备接收，负载均衡设备再将其分发给相应的真实服务器，而从真实服务器发送给客户端的响应报文则直接由交换机返回。相应的工作流程如图 4-9 所示。

图 4-9 DR 方式 L4 负载均衡的工作流程

这种方法没有采用传统的通过查找路由表的转发方式来分发请求报文，而是通过修改目的 MAC 直接路由给服务器，DR 方式也就因此而得名。该方法只要求客户端到服务器的单方向请求报文经过负载均衡设备，负载均衡设备负担较小，不易成为瓶颈，具有更高的处理性能。

2.七层负载均衡

L4 服务器负载均衡在截取数据流以后，对数据包的检查和分析仅局限于 IP 报文头部和 TCP/UDP 报文头部，而并不关心 TCP/UDP 数据包的有效载荷信息。而 L7 服务器负载均衡则要求负载均衡设备除了支持基于四层的负载均衡以外，还要解析数据包中四层以上的信息，即应用层的信息，例如解析 HTTP 内容，从而在数据包中提取出 HTTP URL 或者 Cookie 信息，用来作为负载均衡的依据。

L7 服务器负载均衡通过内容分析控制应用层服务分发，提供了一种高层的访问流量控制方式，与此前传统的 L4 负载均衡相比，L7 负载均衡具有如下优点。

（1）能够根据数据包内容（例如判断数据包是图像文件、压缩文件或者多媒体文件等）把数据流量引向能够处理相应内容的服务器，提高系统可管理性和灵活性。

（2）能够根据连接请求的数据类型（例如根据 URL 判定用户发来的请求是和普通文本、图像等静态文档相关，还是和 ASP、CGI 等动态文档相关），把其引向相应的服务器处理，在提高系统性能的同时有助于改善安全性。

（3）能够根据应用层载荷保证会话持续性，相对于 L4 服务器负载均衡采用的基于地址的持续性保证方式更加精细。

L7 负载均衡的典型组网如图 4-10 所示。

图 4-10 L7 负载均衡的典型组网

如图 4-10 所示，L7 服务器负载均衡与 NAT 方式 L4 服务器负载均衡在实现上非常类似，其主要区别是增加了服务组的概念。服务组是一个逻辑概念，是指依据一些公共属性将多台服务器划分为不同的组。例如：可以将服务器划分为静态资料存储服务器组和动态交换服务器组，或者划分为音乐服务器组、视频服务器组和图片服务器组等，根据应用层属性划分的服务器组内部各台服务器更容易有相近的性能和特性。

我们结合图示 4-11 了解一下 L7 服务器负载均衡的工作原理。

图 4-11 L7 负载均衡的工作流程

（1）客户端与位于服务器集群前端的负载均衡设备之间建立 TCP 连接。

（2）客户端将发送到虚拟 IP 地址的服务请求发送给负载均衡设备，负载均衡设备接收客户端请求。

（3）负载均衡设备通过服务器可用性验证、会话持续性保证、服务组匹配策略、负载均衡算法调度等步骤，选择出负责响应和处理该请求的真实服务器。

（4）负载均衡设备利用客户端地址与真实服务器建立 TCP 连接。

（5）负载均衡设备将客户端请求报文的目的地址重写为真实服务器的 IP 地址，并将该请求发送给相应的服务器。

（6）真实服务器向负载均衡设备响应服务。

（7）报文在通过负载均衡设备时，源地址被还原为虚拟 IP 地址，再返回给客户端。

L7 服务器负载均衡在负载均衡过程中能够对应用层协议进行深度识别，带来了很多更精细化均衡的可能，但它也对系统性能提出了非常高的要求，通常需要采用专用芯片以硬件电路的方式实现。同时，它需要针对每种应用层协议都配备相应的独立的识别机制，这极大地限制了 L7 服务器负载均衡的应用扩展性。由于 HTTP 协议应用广泛且协议相对简单，所以当前 L7 负载均衡技术对 HTTP 请求进行负载均衡的商用能力最强。

还要说明的是，在实际应用中，L4 负载均衡和 L7 负载均衡往往是搭配使用的，当然最好是在同一台负载均衡设备上兼具四层和七层功能。负载均衡设备首先从报文中提取 IP 地址和端口号，进行四层负载均衡，如果发现确有必要进行进一步的基于报文内容的转发，再实施七层负载均衡操作。
4.3.4 链路负载均衡

前面我们了解了服务器负载均衡，下面还要介绍一种负载均衡，叫做链路负载均衡。这是指通过动态算法在多条网络链路中进行负载均衡。

为了规避运营商网络出口故障导致的网络可用性风险，解决网络带宽不足导致的网络访问失效等问题，企业用户通常会同时租用两家或者更多家运营商网络。在这种情况下，问题就是如何合理地运用这多个运营商的网络出口。传统的基于策略的路由可以在一定程度上解决问题，但是配置不方便，也难以动态适应网络架构变化。最主要的是，这种方法无法根据带宽的实际使用情况动态调整报文分发，造成空闲链路吞吐能力的浪费。因此，链路负载均衡被提出来，希望能够解决传统路由技术存在的这一系列问题。

链路负载均衡根据业务流量的方向可以分为 Outbound 链路负载均衡和 Inbound 链路负载均衡两种情况。其中，Outbound 链路负载均衡主要解决的是企业内部业务系统访问外部互联网服务时如何在多条不同的链路中动态分配和负载均衡的问题；Inbound 链路负载均衡主要解决的是位于互联网外部的用户如何在访问企业内部网站和业务系统时动态地在多条链路上平衡分配，并在一条链路中断时能够智能地自动切换到另一条可用链路。

链路负载均衡与服务器负载均衡之间的主要区别是承担负载的对象不同，单就负载均衡设备而言，其关键技术、部署方式等内容都具有类似之处。其中，在负载均衡调度算法方面，链路负载均衡有一些特有算法，例如就近链路选择算法、基于链路带宽的调度算法等。特别是就近链路选择算法，能够在链路负载均衡过程中，实时探测链路的状态，并根据探测结果选择最优链路，保证流量通过最优链路转发。就近链路选择算法对链路状态的探测可以通过链路健康性检测实现，例如通过发送 DNS 报文和 ICMP 报文、建立 TCP 半开连接等方法在验证链路可达性的同时获得相关的就近链路计算参数。在实现中，就近链路计算参数主要包括：链路物理带宽、链路成本（例如链路月租）、链路延迟时间、路由跳数等。就近链路选择算法也可以根据这些参数进行加权计算，然后根据计算结果判断链路的优劣。

1.Outbound 链路负载均衡

当内网和外网之间存在多条链路时，Outbound 链路负载均衡可以实现在多条链路上分担内网用户访问外网服务器流量的功能，其典型组网如图 4-12 所示。

图 4-12 Outbound 链路负载均衡的典型组网

在图 4-12 中，主要元素包括如下几项。

（1）负载均衡设备：负责将内网到外网的流量在多条物理链路上分发。

（2）物理链路：网络服务器提供商（ISP）提供的实际通信链路。

（3）虚拟 IP 地址：负载均衡设备对外提供的虚拟 IP 地址，用做用户发送报文的目的地址。

Outbound 链路负载均衡的原理是将负载均衡设备的虚拟 IP 地址作为内网用户发送报文的目的地址。用户在将访问虚拟 IP 地址的报文发送给负载均衡设备后，负载均衡设备通过链路选择算法选择出最佳的物理链路，并将内网访问外网的业务流量分发到该链路上。相应的工作流程如图 4-13 所示。

图 4-13 Outbound 链路负载均衡的工作流程

Outbound 链路负载均衡的技术特点包括如下几项。

（1）通过结合 NAT 技术进行组网，不同链路使用不同源 IP 地址，从而能够保证往返报文均经由同一条链路。

（2）通过健康性检测，可以检测链路上任意节点的连通性，从而有效地保证整条路径的可达性。

（3）通过负载均衡调度算法的调度，可以在多条链路间均衡流量，例如利用基于带宽的算法优化带宽利用、利用就近链路选择算法选择最优链路。

2.Inbound 链路负载均衡

前面提到，Inbound 链路负载均衡的主要作用是在多条链路上均衡调度外网用户访问企业内部网站和业务系统时的流量，并在一条链路中断时能够智能地自动切换到另一条可用链路。其典型组网如图 4-14 所示。

图 4-14 Inbound 链路负载均衡的典型组网

如图 4-14 所示，Inbound 链路负载均衡的实现方案虽然与 Outbound 链路负载均衡在很多方面具有相似性，但是因为针对的是不同传输方向上的业务流量，因此部分功能有如下几点区别。

（1）负载均衡设备：负责引导外网流量通过不同的物理链路转发到内网，实现流量在多条物理链路上的分发。同时，负载均衡设备还需要作为待解析域名的权威名称服务器。

（2）物理链路：网络服务器提供商（ISP）提供的实际通信链路。

（3）本地 DNS 服务器：负责处理本地用户发送的 DNS 解析请求，将该请求转发给作为权威名称服务器的负载均衡设备。

Inbound 链路负载均衡的原理是将负载均衡设备作为权威名称服务器，用于记录域名与内网服务器 IP 地址之间的映射关系（即域名的 A 记录）。在本书第 5 章我们会了解到，一个域名会被映射为多个 IP 地址，每个 IP 地址则对应一条物理链路。当外网用户通过域名方式访问内网服务器时，本地 DNS 服务器依照递归原则会向负载均衡设备请求域名解析，负载均衡设备通过就近链路选择算法筛选、ISP 选择等步骤，选择出最佳的物理链路，并将通过该链路与外网连接的接口 IP 地址作为 DNS 域名解析结果反馈给外网用户。相应的工作流程如图 4-15 所示。

图 4-15 Inbound 链路负载均衡的工作流程

Inbound 链路负载均衡通过和服务器负载均衡相配合，可以同时实现多条链路间的均衡和多台服务器间的均衡。另一种应用方式是通过动态的链路选择算法，最终实现以链路最优为基础的服务器负载均衡。



4.4 开源负载均衡软件

当前，业界已经有很多成熟的系统和软件用于实现集群的负载均衡，其中使用最为广泛的包括主要用于实现四层负载均衡的 LVS 和主要用于实现七层负载均衡的 Nginx，它们都是在开源社区的支持下研发的负载均衡软件。
4.4.1 LVS

LVS（Linux Virtual Server）是由国防科学技术大学章文嵩在 1998 年 5 月发起的遵循 GPL 许可证的开源软件项目，其目标是为 Linux 集群系统研发高性能、高可用的负载均衡解决方案。当前，LVS 已经成为 Linux 标准内核的一部分，2.4 版本以后的 Linux 内核中已经完全内置了 LVS 的各个模块，用户可以直接使用 LVS 提供的各项功能。从项目创立至今，LVS 已经发展成为一个非常成熟的技术项目，可以被用于提供高可扩展的、高可靠的、高可服务的 Linux 集群系统服务，很多著名的网站和组织都使用了 LVS 技术，例如：Linux 的门户网站、向 RealPlayer 提供音频视频服务的 Real 公司、全球最大的开源网站 SourceForge 等。

负载均衡系统通常位于整个集群的最前端，由一台或者多台负载调度器组成，LVS 就安装和部署在负载均衡调度器上。安装了 LVS 负载调度器的主要功用类似于路由器，它含有完成 LVS 负载均衡功能所需的路由表，通过其中的路由信息将用户请求分发给集群中的应用服务器。同时 LVS 负载调度器还需要监测各台应用服务器的工作情况，并根据服务器的状态是否正常可用随时更新 LVS 路由表。

LVS 的核心是 IP 负载均衡，实现该功能的是 IPVS 模块，它被安装在负载调度器上并虚拟出一个 IP 地址提供给用户，用户必须通过该虚拟 IP 地址才能够访问到集群提供的应用服务，即所有的用户请求都首先经由虚拟 IP 地址达到负载调度器，然后负载调度器将从应用服务器列表中选择一个合适的节点响应用户请求。根据调度器将请求发送到应用服务器节点以及应用服务器返回数据给用户的方式上存在的差异，IPVS 具有 NAT（Network Address Translation）、TUN（IP Tunneling）、DR（Direct Routing）等不同的实现方式。其中，除了本书介绍过的 NAT、DR 方式外，TUN 是指将一个 IP 报文封装在另一个 IP 报文中的技术，IPVS 利用该技术先将用户请求进行封装再转发给应用服务器，响应内容则直接从应用服务器返回给用户。采用 TUN 方式，LVS 负载调度器只负责用户请求的调度而不处理响应数据，仅需耗费用于建立 IP 隧道的开销从而具有较高的性能，但是 TUN 技术的实现对服务器要求较高，即所有的服务器必须支持「IP Tunneling」或「IP Encapsulation」协议。另外，LVS 能够提供的负载均衡调度算法也比较丰富，例如轮询（Round Robin）、加权轮询（Weighted Round Robin）、最小连接（Least Connection）、加权最小连接（Weighted Least Connection）等。

LVS 的主要特点包括如下几点。

（1）性能好。LVS 集成在操作系统内核之中，在网络协议栈第四层对用户请求进行分发，自身没有流量的产生，因此具有极高的性能。

（2）配置简单。LVS 已经被广大的 Linux、FreeBSD 操作系统所支持，配置文件比较简单，操作便捷，降低了配置出错的几率。

（3）工作稳定。LVS 在实际应用中已被广泛证明具有极强的可靠性，同时它具有完整的双机热备方案，如 LVS+Keepalived 和 LVS+Heartbeat 等。

当前，除了 IP 负载均衡外，LVS 还实现了 KTCPVS（Kernel TCP Virtual Server）用于在网络协议栈的第七层进行负载均衡操作，以及其他一些扩展功能模块。LVS 官方网站的网址是 http://www.linuxvirtualserver.org，网站上提供了最新版本的 LVS 的下载链接和相关的软件手册。
4.4.2 Nginx

Nginx（读作 engine-x）是一款高性能的 HTTP 和反向代理服务器，同时它也是一个 IMAP/POP3/SMTP 代理服务器。Nginx 于 2002 年由俄罗斯人 Igor Sysoev 开发，它遵循的是类 BSD 许可证（2-clause BSD-like license），其第一个公开版本 0.1.0 发布于 2004 年 10 月 4 日。2011 年 11 月 15 日，Nginx 的 1.0.10 稳定版正式发布。Nginx 具有非常优越的性能，特别是极高的并发处理能力，因此获得了众多互联网网站的青睐，根据互联网监测公司 Netcraft 的统计报告，截至 2011 年 11 月，全球最忙碌的 100 万个 Web 站点中就有 8.01% 的份额采用了 Nginx 软件，包括 WordPress、Hulu、Github、Ohloh、SourceForge、WhitePages、TorrentReactor 等。

Nginx 实现了完善的 HTTP 服务器功能，在实际的网站部署中，它经常被用于处理网络协议栈七层的负载均衡问题。Nginx 负载均衡的核心是 Upstream 模块，当 Nginx 接收到用户发来的 HTTP 请求后，它将创建一个到后端应用服务器的 Upstream 请求，待应用服务器发送回响应数据后，Nginx 再将后端 Upstream 中的数据转发给用户。Upstream 支持的负载调度算法主要包括基于源 IP 的 Hash、基于目的 URL 的 Hash、基于响应时间的公平调度等。

Nginx 的主要特点包括如下几点。

（1）调度灵活。Nginx 工作在网络协议栈的第七层，能够对 HTTP 应用请求进行解析和分流，支持比较复杂的正则规则，具有更优化的负载调度效果。

（2）网络依赖性低。Nginx 对网络的依赖程度非常低，理论上讲，只要能够 Ping 通就可以实施负载均衡，而且可以有效区分内网和外网流量。

（3）支持服务器检测。Nginx 能够根据应用服务器处理页面返回的状态码、超时信息等检测服务器是否出现故障，并及时将返回错误的请求重新提交到其他节点上。

相对于 LVS，Nginx 主要用于网络七层的调度，在灵活性和有效性方面更具优势，同时它对服务器健康状态的检测也避免了用户访问过程中的连接断线。但是，网络七层信息处理的复杂度也使得 Nginx 在负载能力和稳定性方面与 LVS 相比有较大的差距。另外，它目前只支持 HTTP 应用和 EMAIL 应用，在应用场景上不如 LVS 丰富，而且也不具备现成的双机热备方案。总体而言，实际场景中可以考虑 LVS 和 Nginx 的结合使用，其中将 LVS 部署在前端用于处理四层的负载均衡，当需要更细节的负载调度时再启用 Nginx 以优化调度效果。

Nginx 官方网站的网址是 http://nginx.org/，网站上提供了最新版本的 Nginx 的下载链接和相关的软件手册。
